configfile: "config.yaml"

from itertools import chain
from functools import partial
import os.path
import tempfile
import yaml

from scripts.common import detect_reads, fill_default_values

#Config parameters
fill_default_values(config)

TMP_DIR_ROOT = "/localscratch"
IN = config["data"]
READ_LENGTH = config["read_length"]
BIN = config["bin"]
COG_DB= config["cog_database"]
THREADS = config["threads"]
SCG_DATA = config["scg_data"]
MIN_CONTIG_SIZE = config["concoct_contig_size"]
DESMAN_HAPLOTYPE_NB = config["desman"]["nb_haplotypes"]
DESMAN_REPEAT = config["desman"]["nb_repeat"]
MIN_COV_DESMAN = config["desman"]["min_cov"]
LIST_COGS=list(map(str.rstrip,open(SCG_DATA+"/scg_cogs_min0.97_max1.03_unique_genera.txt").readlines()))

#Autodetect samples and their reads
#Check that sample names are consecutive and all are presented
SAMPLE_DIRS = set(glob_wildcards(os.path.join(IN, "{sample,sample\d+}"))[0])
SAMPLE_COUNT = config.get("count", len(SAMPLE_DIRS))
SAMPLES = list()
for i in range(1, SAMPLE_COUNT + 1):
    sample_name = "sample" + str(i)
    if sample_name not in SAMPLE_DIRS:
        raise WorkflowError("Samples must be consecutive; missing " + sample_name)
    SAMPLES.append(sample_name)

SAMPLE_READS = dict(map(lambda sample: (sample, detect_reads(os.path.join(IN, sample))), SAMPLES))

#Group samples
GROUP_SAMPLES = config["assembly"]["groups"]
#Form /N groups
#FIXME weird behavior if not a multiple
if type(GROUP_SAMPLES) == str:
    if not GROUP_SAMPLES[0] == "/":
        raise WorkflowException("Wrong format of assembly groups")
    group_cnt = int(GROUP_SAMPLES[1:])
    group_size = SAMPLE_COUNT // group_cnt
    GROUP_SAMPLES = [["sample"+str(j) for j in range(i, min(i + group_size, SAMPLE_COUNT + 1))]
                     for i in range(1, SAMPLE_COUNT, group_size)]
else:
    USED_SAMPLES = set()

    def process_sample(i):
        if type(i) == int:
            res = "sample" + str(i)
        elif type(i) == str and i.startswith("sample"):
            res = i
        else:
            raise WorkflowException("Samples in groups must be named either sampleXX or XX, but got " + str(i))
        return res

    def process_group(g):
        if type(g) == list:
            res = list(map(process_sample, g))
        elif type(g) == str and g == "*": #Replace the wildcard group with unused samples
            res = [sample for sample in SAMPLES if sample not in USED_SAMPLES]
        else:
            raise WorkflowException("Groups must be either list of samples or a wildcard *, but got " + str(g))
        USED_SAMPLES.update(res)
        return res

    GROUP_SAMPLES = list(map(process_group, GROUP_SAMPLES))

    #Add a single-sample group from the rest of the samples
    for sample in SAMPLES:
        if sample not in USED_SAMPLES:
            GROUP_SAMPLES.append([sample])

#Dictionary: {group name: [samples of the group]}
#Can be iterated to retrieve all group names
GROUPS = dict()
group_id = 1
for group in GROUP_SAMPLES:
    if len(group) == 1:
        key = group[0] #Groups of a single sample are simply called sampleXX
    else:
        key = "group" + str(group_id)
        SAMPLE_READS[key] = ([SAMPLE_READS[s][0] for s in group], [SAMPLE_READS[s][1] for s in group])
        group_id += 1
    GROUPS[key] = group


#Helpers for locating input files
#Returns all filepaths with left/right reads for a sample/group/bin/etc, used as Snakemake input
def reads_input(dict):
    return (partial(dict, 0), partial(dict, 1))

def sample_reads(dir, wildcards):
    return SAMPLE_READS[wildcards["sample"]][dir]

left_sample_reads, right_sample_reads = reads_input(sample_reads)

def samples_yaml():
    libs = []
    for s in SAMPLES:
        info = {}
        info["left reads"] = [SAMPLE_READS[s][0]]
        info["right reads"] = [SAMPLE_READS[s][1]]
        info["type"] = "paired-end"
        info["orientation"] = "fr"
        libs.append(info)

    return yaml.dump(libs, default_style='"', default_flow_style=False)

def group_reads(dir, wildcards):
    return SAMPLE_READS[wildcards["group"]][dir]

left_reads, right_reads = reads_input(group_reads)

def is_fastq(wildcards):
    name = getattr(wildcards, "sample", None)
    if not name:
        try:
            name = GROUPS[wildcards.group][0]
        except KeyError:
            name = wildcards.group

    for ext in {".fastq", ".fq", ".fastq.gz", "fq.gz"}:
        if SAMPLE_READS[name][0].endswith(ext):
            return True
    return False

def check_scratch_avail(root):
    if os.path.isdir(root):
        try:
            with tempfile.TemporaryDirectory(dir=root) as temp_dir:
                return True
        except:
            print("Launch with tmpdir failed")
    return False

rule bowtie_index:
    input:   "{path}/{ref}.fasta"
    output:  touch("{path}/{ref}/index.done")
    params:  "{path}/{ref}/index"
    threads: THREADS
    log:     "{path}/{ref}/index.log"
    message: "Building bowtie index for {input}"
    shell:   "bowtie2-build {input} {params} --threads {THREADS} &> {log}"

#consider ignoring reads aligned without their pairs
rule bowtie_align:
    input:   left=left_reads, right=right_reads,
             index="{path}/index.done"
    output:  "{path}/{group,(sample|group)\d+}.bam"
             #temp("{path}/{group,(sample|group)\d+}.bam")
    params:  flag=lambda w: "-q" if is_fastq(w) else "-f",
             left=lambda w: ",".join(expand("{r}", r=left_reads(w))),
             right=lambda w: ",".join(expand("{r}", r=left_reads(w))),
             index="{path}/index",
             align="",#"--no-unal --maxins 1000 --n-ceil 0,0 --np 100500",
             view=""#"-q 10"
    threads: THREADS
    log:     "{path}/{group}.bowtie.log"
    message: "Aligning reads of {wildcards.group} onto {params.index} with bowtie"
    #shell:   "bowtie2 -x {params.index} {params.flag} -p {threads} {params.align}"
    #         " -1 {input.left} -2 {input.right} 2> {log} | samtools view -bh {params.view} - > {output}"
    shell:
        'bowtie2 -x {params.index} {params.flag} -p {threads} {params.align} -1 {params.left} -2 {params.right} 2>> {log} | samtools view -bh {params.view} - > {output}'

rule samtools_sort:
    input:
        "{path}/{name}.bam"
    output:
        "{path}/{name}.sorted.bam"
        #temp("{path}/{name}.sorted.bam")
    threads: THREADS
    log:
        "{path}/{name}.sort.log"
    message: "Sorting {input}"
    run:
        shell("samtools sort --threads %d -T {wildcards.path}/{wildcards.name}.tmp -O bam -o {output} {input} &> {log}" % (threads - 1))
